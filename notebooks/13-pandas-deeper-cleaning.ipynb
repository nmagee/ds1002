{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Data Cleaning II\n",
    "\n",
    "```\n",
    "  University of Virginia\n",
    "  DS1002: Programming for Data Science\n",
    "  Last Updated: October 1, 2023\n",
    "```\n",
    "\n",
    "### PREREQUISITES\n",
    "- data types\n",
    "- pandas dataframes\n",
    "- pandas data cleaning I\n",
    "\n",
    "### OBJECTIVES\n",
    "- Problems with text and categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning in Pandas\n",
    "\n",
    "**Why do we need to clean data?**\n",
    "\n",
    "![](https://ds1002-resources.s3.amazonaws.com/images/workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Type Constraints\n",
    "\n",
    "We need to make sure our variables have the correct data types, other wise we risk compromising our analysis.\n",
    "\n",
    "Example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import `sales.csv`\n",
    "sales = pd.read_csv('https://ds1002-resources.s3.amazonaws.com/data/sales.csv')\n",
    "sales.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to calculate total revenue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Revenue'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This produces some sort of numerical/repeating error we need to solve. Let's examine the data types of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And next let's look at some rows to see what we find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove $ from Revenue columns\n",
    "sales['Revenue'] = sales['Revenue'].str.strip('$')\n",
    "sales['Revenue'] = sales['Revenue'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that Revenue is now an integer\n",
    "assert sales['Revenue'].dtype == 'int'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric or categorical data\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import `marriage_status.csv`\n",
    "marriage_status = pd.read_csv('https://ds1002-resources.s3.amazonaws.com/data/marriage_status.csv')\n",
    "marriage_status.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`0` = Never Married\n",
    "`1` = Married\n",
    "`2` = Separated\n",
    "`3` = Divorced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marriage_status['marriage_status'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculated as a numeric variables when in reality a categorical.  \n",
    "\n",
    "Let's change the the data type to `categorical`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marriage_status['marriage_status'] = marriage_status['marriage_status'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marriage_status.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas now gives summary outputs consistant with a `categorical` variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out of Range Data\n",
    "\n",
    "Out of range data can occur from human error, data collection error, etc.   \n",
    "\n",
    "Let's work through a couple examples\n",
    "\n",
    "**`Movie Ratings`**  \n",
    "\n",
    "consists of `name`, `year`, and `score` (0-10)  \n",
    "\n",
    "**`User Signups`**  \n",
    "\n",
    "consists of `subscription_date`, `user_name`, `country`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import movie_ratings.csv\n",
    "\n",
    "movies = pd.read_csv('https://ds1002-resources.s3.amazonaws.com/data/movies.csv')\n",
    "movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data viz\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(movies['Score'])\n",
    "plt.title('Average rating of top 50 movies (0-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import `user_signups`\n",
    "users = pd.read_csv('https://ds1002-resources.s3.amazonaws.com/data/user_signups.csv')\n",
    "users.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datetime\n",
    "import datetime as dt\n",
    "\n",
    "#convert object to date\n",
    "users['subscription_date'] = pd.to_datetime(users['subscription_date'])\n",
    "users.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert object to date\n",
    "users['subscription_date'] = pd.to_datetime(users['subscription_date']).dt.date\n",
    "users.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_date = dt.date.today()\n",
    "users[users['subscription_date'] > today_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to deal without out of range data\n",
    "\n",
    "1. Drop data\n",
    " - not advised unless very small propotion of data\n",
    " - may be removing otherwise important data\n",
    "\n",
    "2. Treat data as missing\n",
    "- can then impute data\n",
    "\n",
    "3. Set a custom value depending on the business assumptions \n",
    "\n",
    "**always document decision and steps!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the `movies` df\n",
    "\n",
    "movies[movies['Score'] > 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by filtering\n",
    "movies1 = movies[movies['Score'] <= 10]\n",
    "\n",
    "#check that values were dropped\n",
    "movies1.sort_values(['Score'], ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with .drop() function\n",
    "movies2 = movies.drop(movies[movies['Score'] > 10].index)\n",
    "movies2.sort_values('Score', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Score > 10 to 10\n",
    "movies.loc[movies['Score']> 10, 'Score'] = 10\n",
    "\n",
    "assert movies['Score'].max() <= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set out of range values to a custom number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data & Membership Constraints\n",
    "\n",
    "- Has a predefined set of categories\n",
    "\n",
    "- Value can only be one of the membership categories\n",
    "\n",
    "- Often coded as numbers for further analysis techniques (like machine learning)\n",
    "\n",
    "### Concerns in categorical data\n",
    "\n",
    "1. Errors occur when observations have values that go beyond the predefined catogories\n",
    "\n",
    "2. Errors also occur with inconsistent fields\n",
    "\n",
    "3. Needing to collapse categories\n",
    "\n",
    "4. Data type not being defined as 'category'\n",
    "\n",
    "### Fixing observations that go beyond predefined categories\n",
    "\n",
    "- We can drop, remap, or infer categories to fix\n",
    "\n",
    "- We covered simple examples of these during Pandas Data Cleaning I\n",
    "\n",
    "- Here is more complex example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv's\n",
    "\n",
    "study = pd.read_csv('https://ds1002-resources.s3.amazonaws.com/data/study.csv')\n",
    "categories = pd.read_csv('https://ds1002-resources.s3.amazonaws.com/data/blood_categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check for errors with using joins.\n",
    "\n",
    "![](https://ds1002-resources.s3.amazonaws.com/images/joins.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So a left anti join between study and categories would give us this:**\n",
    "\n",
    "![](https://ds1002-resources.s3.amazonaws.com/images/antijoin.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An inner join between study and category would give us:**\n",
    "\n",
    "![](https://ds1002-resources.s3.amazonaws.com/images/innerjoin.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's do this in python**\n",
    "\n",
    "**`.set()`**  \n",
    "**`.difference()`**\n",
    "\n",
    "[Geeks for Geeks](https://www.geeksforgeeks.org/python-set-difference/)\n",
    "\n",
    "*Note: these are from python not pandas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find inconsistent categories\n",
    "\n",
    "inconsistent_categories = set(study['blood_type']).difference(categories['blood_type'])\n",
    "inconsistent_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find inconsistent rows\n",
    "\n",
    "inconsistent_rows = study['blood_type'].isin(inconsistent_categories) # gives a boolean series\n",
    "study[inconsistent_rows] # subset study dataframe based on boolean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one way to drop inconsistent rows (other ways in pandas cleaning I)\n",
    "consistent_data = study[~inconsistent_rows]\n",
    "consistent_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing value inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import `marriage_status` dataset\n",
    "marriage = pd.read_csv('https://ds1002-resources.s3.amazonaws.com/data/marriage_status.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marriage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marriage['marriage_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example we can either capitalize or lowercase the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capitalize\n",
    "marriage['marriage_status'] = marriage['marriage_status'].str.upper()\n",
    "marriage['marriage_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase\n",
    "marriage['marriage_status'] = marriage['marriage_status'].str.lower()\n",
    "marriage['marriage_status'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collapsing data into categories\n",
    "\n",
    "* Often we will need to distill continuous data into categories \n",
    "* Categories should have evidence-based backing behing them\n",
    "* Cateogires can increase interpretability but can also lose valuable information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = pd.read_csv('https://ds1002-resources.s3.amazonaws.com/data/income.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`.qcut()`**\n",
    "\n",
    "* automatically divides data into categories based on the argument `q` and the distribution of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['0-100K', '100K-250K', '250K-500K', '500K+']\n",
    "income['income_group'] = pd.qcut(income['household_income'], q = 4,\n",
    "                                     labels = group_names)\n",
    "\n",
    "income[['income_group', 'household_income']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`.cut()`**\n",
    "\n",
    "* Allows you to use categories cut-off ranges with the `bins` arguement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = [0, 100000, 500000, np.inf]\n",
    "group_names = ['0-100K', '100K-500K', '500K+']\n",
    "income['income_group'] = pd.cut(income['household_income'], bins = ranges,\n",
    "                                     labels = group_names)\n",
    "\n",
    "income[['income_group', 'household_income']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map categories into fewer ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computer = pd.read_csv('https://ds1002-resources.s3.amazonaws.com/data/computer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to collapse the `operating system` column into `'DesktopOS', 'MobileOS'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary\n",
    "mapping = {'Microsoft': 'DesktopOS', 'MacOS': 'DesktopOS', 'Linux': 'DesktopOS', 'IOS': 'MobileOS', 'Android': 'MobileOS'}\n",
    "\n",
    "# use `.replace`\n",
    "computer['operating_system_category'] = computer['operating_system'].replace(mapping)\n",
    "computer['operating_system_category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Data\n",
    "\n",
    "* Common type of data\n",
    "\n",
    "* Common text data problems are:\n",
    "1) data inconsistency\n",
    "2) fixed length violations\n",
    "3) typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones = pd.read_csv('https://ds1002-resources.s3.amazonaws.com/data/phone_numbers.csv')\n",
    "phones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally we want to remove dashes, have each phone number start with the full country code, and remove phone numbers that don't have full values listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the '+' with '00'\n",
    "phones['phone_number'] = phones['phone_number'].str.replace('+', '00')\n",
    "phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the '-' with nothing\n",
    "phones['phone_number'] = phones['phone_number'].str.replace('-', '')\n",
    "phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace phone numbers with lower than 10 digits to NaN\n",
    "digits = phones['phone_number'].str.len() # gets the length of the each phone number\n",
    "phones.loc[digits < 10, 'phone_number'] = np.nan # subset phone numbers with less than 10 digits, replace with NaN\n",
    "phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking data with assert statements\n",
    "\n",
    "# find length of each row in phone_number columns\n",
    "sanity_check = phones['phone_number'].str.len()\n",
    "\n",
    "# assert minimum phone_number lenth is 10\n",
    "assert sanity_check.min() >= 10\n",
    "\n",
    "# assert all number do not have a '+' or '-'\n",
    "assert phones['phone_number'].str.contains('+|-').any() == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More complicated regular expression (`regex`) examples\n",
    "\n",
    "* Regular expressions give us the ability to search for any pattern in text data, like only digits for example\n",
    "\n",
    "* They are like control + find in your browser, but more dynamic and robust\n",
    "\n",
    "[regex blog](https://www.analyticsvidhya.com/blog/2021/07/regular-expressions-in-python-a-beginners-guide/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones_complex = pd.read_csv('https://ds1002-resources.s3.amazonaws.com/data/phone_numbers_complex.csv')\n",
    "phones_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace letters with nothing\n",
    "\n",
    "phones_complex['phone_number'] = phones_complex['phone_number'].str.replace(r'\\D+', '') #\\D+ mean anything that is not a digit, found in regex library\n",
    "phones_complex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Uniformity\n",
    "\n",
    "* We want data within columns to have the same units (temperature, weight, money)\n",
    "\n",
    "* Or data, as as dates, to have the same format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = pd.read_csv('https://ds1002-resources.s3.amazonaws.com/data/temperatures.csv')\n",
    "temps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's look at graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create a scatter plot\n",
    "plt.scatter(x = 'date', y = 'temperature', data = temps)\n",
    "\n",
    "# create title, xlabel, and ylabel\n",
    "plt.title('Temperatures in Celsius March 2019 - NYC')\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('temperature (degrees Celsius)')\n",
    "plt.xticks(rotation = 90)\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert farhenheit data to celsius**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_fah = temps.loc[temps['temperature'] > 40, 'temperature'] # use .loc to subset data above 40\n",
    "\n",
    "temp_cels = (temp_fah - 32) * (5/9) # convert to celsius\n",
    "\n",
    "temps.loc[temps['temperature'] > 40, 'temperature'] = temp_cels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create a scatter plot\n",
    "plt.scatter(x = 'date', y = 'temperature', data = temps)\n",
    "\n",
    "# create title, xlabel, and ylabel\n",
    "plt.title('Temperatures in Celsius March 2019 - NYC')\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('temperature (degrees Celsius)')\n",
    "plt.xticks(rotation = 90)\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean-up Dates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birthdays = pd.read_csv('https://ds1002-resources.s3.amazonaws.com/data/birthdays.csv')\n",
    "birthdays.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `datetime` package is useful for representing dates\n",
    "\n",
    "[How to format dates in python](https://stackabuse.com/how-to-format-dates-in-python/)\n",
    "\n",
    "We also use `pandas.to_datetime`\n",
    "* can recognize more formats automatically\n",
    "* sometimes fails with erroneous or unrecongizable formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts to datetime\n",
    "birthdays['birth_date'] = pd.to_datetime(birthdays['birth_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Doesn't work!**\n",
    "\n",
    "try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birthdays['birth_date'] = pd.to_datetime(birthdays['birth_date'],\n",
    "                                        # attempt to infer format for each date\n",
    "                                        infer_datetime_format = True,\n",
    "                                        # return NA for rows where conversion failed \n",
    "                                        errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birthdays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birthdays['birth_date'] = birthdays['birth_date'].dt.strftime('%d-%m-%Y')\n",
    "birthdays.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ambiguous Data**\n",
    "\n",
    "Is `2019-03-08` in August or March?\n",
    "\n",
    "* Can covnert to `NA` or treat accordingly\n",
    "* Can infer - this is where knowing your data is useful"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
